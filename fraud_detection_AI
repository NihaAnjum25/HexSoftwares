import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier  # Simple ML model
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt
import time

# Step 1: Generate Simple Synthetic Data
# We create fake transaction data: amount, hour of day, and whether it's fraud.
# Fraud: High amounts or unusual hours (e.g., midnight transactions).
def generate_simple_data(n_transactions=5000, fraud_rate=0.1):
    np.random.seed(42)
    
    # Normal transactions
    n_normal = int(n_transactions * (1 - fraud_rate))
    normal_amounts = np.random.normal(50, 20, n_normal)  # Average $50, std $20
    normal_hours = np.random.randint(9, 18, n_normal)    # Business hours (9 AM - 6 PM)
    
    # Fraud transactions
    n_fraud = n_transactions - n_normal
    fraud_amounts = np.random.uniform(500, 2000, n_fraud)  # High amounts
    fraud_hours = np.random.choice([0, 1, 2, 23], n_fraud)  # Late night
    
    # Combine data
    data = {
        'amount': np.concatenate([normal_amounts, fraud_amounts]),
        'hour': np.concatenate([normal_hours, fraud_hours]),
        'is_fraud': np.concatenate([np.zeros(n_normal), np.ones(n_fraud)])
    }
    df = pd.DataFrame(data)
    df = df.sample(frac=1).reset_index(drop=True)  # Shuffle
    
    print(f"Generated {len(df)} transactions, {n_fraud} frauds ({fraud_rate*100:.1f}% fraud rate)")
    return df

# Step 2: Simple Preprocessing
# Scale the numerical features (amount and hour) for better model performance.
def preprocess_data(df):
    # Features: amount and hour
    X = df[['amount', 'hour']].values
    y = df['is_fraud'].values
    
    # Scale features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    return X_scaled, y, scaler

# Step 3: Simple ML Model (Random Forest)
# This is a basic supervised ML model that learns from labeled data to detect fraud.
class SimpleMLDetector:
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=50, random_state=42)  # 50 trees for simplicity
        self.scaler = None
    
    def fit(self, X_train, y_train):
        self.model.fit(X_train, y_train)
    
    def predict(self, X):
        return self.model.predict(X)
    
    def predict_proba(self, X):
        return self.model.predict_proba(X)[:, 1]  # Probability of fraud

# Step 4: Simple DL Model (Basic Neural Network)
# A simple feedforward network that learns patterns for fraud detection.
class SimpleDLDetector:
    def __init__(self, input_dim=2, epochs=20):  # 2 features: amount and hour
        self.input_dim = input_dim
        self.epochs = epochs
        self.model = self._build_model()
        self.scaler = StandardScaler()
    
    def _build_model(self):
        model = Sequential([
            Dense(16, activation='relu', input_shape=(self.input_dim,)),  # Hidden layer with 16 neurons
            Dense(8, activation='relu'),  # Smaller hidden layer
            Dense(1, activation='sigmoid')  # Output: probability of fraud
        ])
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        return model
    
    def fit(self, X_train, y_train):
        X_scaled = self.scaler.fit_transform(X_train)
        self.model.fit(X_scaled, y_train, epochs=self.epochs, batch_size=32, verbose=0)
    
    def predict(self, X):
        X_scaled = self.scaler.transform(X)
        predictions = self.model.predict(X_scaled, verbose=0)
        return (predictions > 0.5).astype(int).flatten()

# Step 5: Simulate Real-Time Detection
# Process data in small batches to mimic real-time analysis (e.g., incoming transactions).
# In real life, this could connect to a stream like Kafka.
def simulate_real_time_detection(df, batch_size=50, delay=0.1):
    # Split data: 70% train, 30% test (for "streaming")
    X, y, scaler = preprocess_data(df)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    
    # Train models on training data
    ml_model = SimpleMLDetector()
    ml_model.fit(X_train, y_train)
    
    dl_model = SimpleDLDetector(input_dim=X.shape[1])
    dl_model.fit(X_train, y_train)
    
    # Simulate streaming: Process test data in batches
    predictions = {'ml': [], 'dl': [], 'true': []}
    print("Simulating real-time detection...")
    
    for i in range(0, len(X_test), batch_size):
        batch_X = X_test[i:i+batch_size]
        batch_y = y_test[i:i+batch_size]
        
        # Predict with ML
        ml_pred = ml_model.predict(batch_X)
        
        # Predict with DL
        dl_pred = dl_model.predict(batch_X)
        
        # Simple ensemble: Average predictions (1 if both agree on fraud)
        ensemble_pred = np.where((ml_pred + dl_pred) >= 1, 1, 0)
        
        predictions['ml'].extend(ml_pred)
        predictions['dl'].extend(dl_pred)
        predictions['true'].extend(batch_y)
        
        # Check for fraud in batch and "alert"
        fraud_count = np.sum(ensemble_pred)
        if fraud_count > 0:
            print(f"Batch {i//batch_size + 1}: Detected {fraud_count} potential frauds!")
        
        time.sleep(delay)  # Simulate processing time
    
    return predictions, y_test  # y_test is full for evaluation

# Step 6: Simple Evaluation
# Check how well the models performed.
def evaluate_predictions(predictions):
    y_true = np.array(predictions['true'])
    y_ml = np.array(predictions['ml'])
    y_dl = np.array(predictions['dl'])
    
    print("\nModel Performance:")
    print(f"ML (Random Forest) Accuracy: {accuracy_score(y_true, y_ml):.4f}")
    print(f"DL (Neural Network) Accuracy: {accuracy_score(y_true, y_dl):.4f}")
    
    # Ensemble accuracy
    y_ensemble = np.where((y_ml + y_dl) >= 1, 1, 0)
    print(f"Ensemble Accuracy: {accuracy_score(y_true, y_ensemble):.4f}")
    
    print("\nDetailed Report for Ensemble:")
    print(classification_report(y_true, y_ensemble))

# Step 7: Simple Visualization
def plot_results(df, predictions):
    y_true = np.array(predictions['true'])
    y_ensemble = np.where((np.array(predictions['ml']) + np.array(predictions['dl'])) >= 1, 1, 0)
    
    plt.figure(figsize=(10, 4))
    
    # Plot 1: Amount distribution
    plt.subplot(1, 2, 1)
    normal_amounts = df[df['is_fraud'] == 0]['amount']
    fraud_amounts = df[df['is_fraud'] == 1]['amount']
    plt.hist(normal_amounts, bins=20, alpha=0.7, label='Normal')
    plt.hist(fraud_amounts, bins=20, alpha=0.7, color='red', label='Fraud')
    plt.xlabel('Amount')
    plt.ylabel('Count')
    plt.legend()
    plt.title('Transaction Amounts')
    
    # Plot 2: Detected frauds in test set
    plt.subplot(1, 2, 2)
    test_indices = range(len(y_true))
    colors = ['red' if pred == 1 else 'blue' for pred in y_ensemble]
    plt.scatter(test_indices, y_true * 1000, c=colors, alpha=0.6)  # Scale y for visibility
    plt.xlabel('Test Transaction Index')
    plt.ylabel('Fraud Label (Scaled)')
    plt.title('Detected Frauds (Red Dots)')
    
    plt.tight_layout()
    plt.show()

# Main: Run Everything
if __name__ == "__main__":
    # Generate data
    df = generate_simple_data(n_transactions=5000, fraud_rate=0.1)
    print(df.head())
    
    # Simulate detection
    predictions, y_test = simulate_real_time_detection(df, batch_size=50, delay=0.05)
    
    # Evaluate
    evaluate_predictions(predictions)
    
    # Plot
    plot_results(df, predictions)
    
    print("\nThis simplified system uses ML (Random Forest) and DL (Neural Network) to detect fraud.")
    print("It processes data in batches for 'real-time' simulation and combines models for better accuracy.")
    print("Easier than rule-based: Learns patterns automatically from data.")
